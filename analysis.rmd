---
title: "Project 2 Deliverable 1"
author: "Raghav Maini, Nick Caseria, Gabriel Correa, Katherine McElroy, Taylor Noren"
date: "2/26/2022"
output: 
  html_document: 
    highlight: tango
    theme: united
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library (C50)
library(gmodels)
library(caret)
library(ggplot2)
library(lattice)
library(Metrics)
```

# Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
basketball <- read.csv("cbb.csv", stringsAsFactors = TRUE)
basketball$TEAM <- NULL
basketball$CONF <- NULL
basketball$SEED <- NULL
summary(basketball)
str(basketball)
```

The data set we have chosen details college basketball statistics from 2013-2019. The data set is broken down by team (355 total). Each team is further categorized by conference. There are a number of statistics that are tracked for each team including the number of games they have played (G) and the number of wins they have (W). The rest of the categories in the data set essentially sum up a teams offensive and defensive efficiency, including turnover percentage, field goal percentage, etc. The goal of our analysis is to use the data set to train a model on the 2013-2019 data to successfully predict the outcomes of the upcoming 2022 march madness tournament. This poses a number of interesting business questions that we hope to answer. First and foremost, there is a rising popularity in sports betting. With college sports in particular, betters are only able to bet on team outcome rather than individual players unlike the NBA. This means our particular data set is a valuable means of assessing how teams might fare this year. Further, college basketball requires comprehensive investment. It is difficult for universities to predict whether or not their program will be successful, and oftentimes coaching contracts are arbitrarily extended based on the performance of one season. Our hope is that using this historical data will shed insight on how colleges should handle their programs in the future and if there are any aspects coaches should focus on when creating their rosters for the next year.

With this question in mind, our response variable for our analysis would be the "POSTSEASON" outcome which details where a team finished at the end of the season. 

```{r}
#Making seed and year factors
#basketball$SEED <- as.factor(basketball$SEED)
#basketball$YEAR <- as.factor(basketball$YEAR)

#Create new columns that have the difference between 3P_O and 3P_D; 2P_O and 2P_D
basketball$Delta_2P <- basketball$X2P_O - basketball$X2P_D
basketball$Delta_3P <- basketball$X3P_O - basketball$X3P_D
summary(basketball)
```

As far as data cleaning goes, there isn't any substantial work to be done. We were able to source this data set on Kaggle which was already accompanied by in depth analysis. With this, the data was essentially cleaned and ready to use. However, we decided to make a couple of key changes. Firstly, we decided to make SEED and YEAR factors. Given that SEED and YEAR both have a limited number of outcomes, this provides us a stronger basis for considering how 1 seeds vs 2 seeds, etc. perform against each other as well as how our predictions change from year to year.

Further, we decided to create two new columns: Delta_3P and Delta_2P. These detail the differential between how many 3 point shots and 2 point shots they allow to score vs how many they actually score themselves. The goal of creating these columns is to assess how teams generally fare against their opposition in terms of these shots. A negative delta implies that they, on average, are worse than their competition while a positive delta implies the opposite. 

## Creating numeric reponse variable column

```{r}
basketball$POSTSEASON_NUM <- ifelse(basketball$POSTSEASON == "R64", 1, ifelse(basketball$POSTSEASON == "R32", 2, ifelse(basketball$POSTSEASON == "S16", 3, ifelse(basketball$POSTSEASON == "E8", 4, ifelse(basketball$POSTSEASON == "F4", 5, ifelse(basketball$POSTSEASON == "2ND", 6, ifelse(basketball$POSTSEASON == "Champions", 7, 0)))))))
basketball$POSTSEASON_NUM[is.na(basketball$POSTSEASON_NUM)] <- 0
basketball$POSTSEASON <- NULL
summary(basketball)


success_eval <- data.frame(matrix(ncol=6, nrow=1718))
colnames(success_eval) <- c("LR", "kNN", "ANN", "SVM", "RT", "Actual")


```

## Split Data into Training Set and Validation Set

```{r}
#70 - 30 Split
set.seed(656)
train_set <- sample(1:nrow(basketball), 0.7*nrow(basketball))

#Training set 
tr <- basketball[train_set, ]
x_tr <- basketball[train_set, -23] #x only 
y_tr <- basketball[train_set, 23] # y only

#Validation set
val <- basketball[-train_set, ]
x_val <- basketball[-train_set, -23]  
y_val <- basketball[-train_set, 23]  

head(tr)


```

# Linear Regression

```{r}
if(!"caret" %in% installed.packages()){install.packages("caret")}
library(caret)

# Simple linear regression

m1 <- lm(POSTSEASON_NUM ~ G + ADJOE + ADJDE + BARTHAG + TOR + DRB + FTR + WAB + Delta_2P + Delta_3P, data = tr)

summary(m1)

#  Step 2. Making predictions 

pred4 <- predict(m1, x_val)

#Creating predict interval 
predict(m1, x_val, interval ="prediction", level= 0.95)


#  Step 3. Evaluating the model performance   
#          Put postResample result in the object, result     

# Evaluating model performance
postResample(pred4, y_val)
md1_result <- postResample(pred4, y_val)

#Residual Plot
#attach(tr)
#require(gridExtra)
#library(gridExtra)
#plot1 <- ggplot(data = tr, aes(x_tr, resid(m1))) + geom_point() + geom_smooth()
#nrow(residuals(m1))
#nrow(x_tr)
#plot1

res <- resid(m1)
plot(fitted(m1), res)
abline(0, 0)
```



#Creating Prediction Variable
```{r}

```


# kNN

```{r}
library(class)
library(caret)
set.seed(656)
trup <- upSample(x=tr[,-ncol(tr)],
y=as.factor(tr$POSTSEASON_NUM))

valup <- upSample(x=val[,-ncol(val)],
y=as.factor(val$POSTSEASON_NUM))

postseason_test_pred <- knn(train = trup, test = valup, cl = trup$Class, k=43)
rmse(as.numeric(valup$Class), as.numeric(postseason_test_pred))
```


```{r}
#tr , val
set.seed(656)
ctrl <- trainControl(method="repeatedcv", repeats=3)
knnFit <- train(POSTSEASON_NUM ~ ., data = basketball, method = "knn", trControl=ctrl, preProcess = c("center", "scale"), tuneLength = 20)
knnFit
```

# Support Vector Machine
```{r}
library(kernlab)
library(caret)

rank_classifier_vanilla <- ksvm(POSTSEASON_NUM ~., data = tr,
                         kernel = "vanilladot", C = 1)

## look at basic information about the model
# rank_classifier_vanilla

rank_predictions_vanilla <- predict(rank_classifier_vanilla, val)

# table(rank_predictions_vanilla, as.factor(y_val))
# rank_predictions_vanilla
agreement_vanilla <- rank_predictions_vanilla == y_val
# table(agreement_vanilla)
prop.table(table(agreement_vanilla))
# success_eval$SVM <- rank_predictions_vanilla

rmse(as.numeric(rank_predictions_vanilla), as.numeric(y_val))


```
## Vanilla SVM Stats

RMSE: `r rmse(as.numeric(rank_predictions_vanilla), as.numeric(y_val))`


# Creating the Regression Tree
```{r}
# STEP 1: Create decision tree using regression
buckets <- rpart(POSTSEASON_NUM ~ G + W + ADJOE + ADJDE + BARTHAG + EFG_O + TOR + ORB + DRB + FTR + ADJ_T + WAB, method = "anova", data = basketball)

# STEP 2: Plot and Print out results for decision tree using regression from above

rpart.plot(buckets, uniform = TRUE,
          main = "Predicting Postseason Breadth") 

print(buckets)

# STEP 3: Create test data (we will use ours from above already created)

val <- basketball[-train_set, ]
x_val <- basketball[-train_set, -23]  
y_val <- basketball[-train_set, 23] 

# STEP 4: Predict Post Season Breadth off of our train data set

postseason_predictions <- predict(buckets, tr, method = "anova")

# STEP 5: Visualizations!
table(postseason_predictions,tr$POSTSEASON_NUM)

# STEP 6: Correlation!
cor(postseason_predictions,tr$POSTSEASON_NUM)

# STEP 7: Assign the Regression Tree output to success_eval column


success_eval$RT <- postseason_predictions
```